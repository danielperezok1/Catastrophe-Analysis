# Catastrophe-Analysis

##  Contexto

Durante el procesamiento del mes **junio de 2020 (202006)**, el equipo de Data Warehousing inform√≥ un **error cr√≠tico**: m√∫ltiples variables quedaron con **valor 0** en lugar de sus valores reales. Esta falla impact√≥ directamente en la calidad del dataset usado para entrenar modelos de predicci√≥n de bajas.


## Hip√≥tesis

> Si reimputamos las variables rotas (en cero) utilizando distintas t√©cnicas de imputaci√≥n, el modelo deber√≠a mejorar su performance y generar una mayor ganancia econ√≥mica en la campa√±a de retenci√≥n proactiva.


## üß† Sesgos Cognitivos 

###  Sesgo de Confirmaci√≥n

> Tendencia a interpretar resultados que confirmen nuestras creencias previas, en este caso, que imputar **deber√≠a mejorar** el modelo.

###  Mitigaci√≥n del sesgo

- Comparaci√≥n objetiva entre m√©todos usando m√©tricas cuantitativas como **ganancia acumulada**.
- Evaluaci√≥n con criterio **ceteris paribus**, manteniendo todo el resto del workflow sin cambios.

---

## üî¨ Procedimiento Experimental

Se probaron **cuatro alternativas de imputaci√≥n** sobre las variables rotas del per√≠odo 202006:

1. **CEROS**
   - No se modifica el dataset. Las variables rotas permanecen en cero.
2. **NA**
   - Los ceros se reemplazan por `NA`, confiando en que **LightGBM** maneje internamente los valores faltantes.
3. **Interpolaci√≥n Lineal**
   - Se reconstruyen los valores faltantes usando una recta entre los valores de los meses anterior y posterior.
   - Se aplica cliente por cliente, por variable afectada.
4. **MICE** (Multiple Imputation by Chained Equations)
   - Imputa los valores faltantes usando otras variables del cliente (edad, antig√ºedad, cantidad de productos, etc.).

---

## üìä Resultados

- Las **curvas de ganancia acumulada** para los cuatro m√©todos muestran un comportamiento **pr√°cticamente id√©ntico**.
- Todos los modelos alcanzan su **m√°ximo de ganancia en el mismo punto**.
- Se observa que el ordenamiento de los clientes por probabilidad de **BAJA+2** es consistente entre m√©todos.

---

## üìà Conclusiones

- **No hay diferencias  en ganancia** entre los m√©todos de imputaci√≥n.
- Se puede priorizar la t√©cnica **m√°s simple, r√°pida y reproducible**.
- Las estrategias m√°s recomendables:  imputar como `NA` si se utiliza un modelo que maneja faltantes (ej. LightGBM).

---

## üí° Recomendaci√≥n

> En contextos donde las variables rotas afectan un √∫nico per√≠odo, y el modelo permite trabajar con valores faltantes, **imputar con `NA` es suficiente**. No se justifica el uso de t√©cnicas m√°s complejas si no mejoran significativamente la m√©trica objetivo.

---



